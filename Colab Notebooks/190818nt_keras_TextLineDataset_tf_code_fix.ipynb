{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflowのkerasバグ対応\n",
    "https://github.com/tensorflow/tensorflow/issues/24520\n",
    "\n",
    "C:\\Users\\%USERNAME%\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py  \n",
    "line: 237  \n",
    "\n",
    "Before\n",
    "```Python\n",
    "def standardize_single_array(x, expected_shape=None):\n",
    "  \"\"\"Expand data of shape (x,) to (x, 1), unless len(expected_shape)==1.\"\"\"\n",
    "  if x is None:\n",
    "    return None\n",
    "\n",
    "  if (x.shape is not None\n",
    "      and len(x.shape) == 1\n",
    "      and (expected_shape is None or len(expected_shape) != 1)):\n",
    "    if tensor_util.is_tensor(x):\n",
    "      x = array_ops.expand_dims(x, axis=1)\n",
    "    else:\n",
    "      x = np.expand_dims(x, 1)\n",
    "  return x\n",
    "```\n",
    "\n",
    "After  \n",
    "```Python\n",
    "def standardize_single_array(x, expected_shape=None):\n",
    "  \"\"\"Expand data of shape (x,) to (x, 1), unless len(expected_shape)==1.\"\"\"\n",
    "  if x is None:\n",
    "    return None\n",
    "  #-------------------------------------\n",
    "  if tensor_util.is_tensor(x):\n",
    "    x_shape_ndims = array_ops.rank(x)\n",
    "    return x\n",
    "  #-------------------------------------\n",
    "  if (x.shape is not None\n",
    "      and len(x.shape) == 1\n",
    "      and (expected_shape is None or len(expected_shape) != 1)):\n",
    "    if tensor_util.is_tensor(x):\n",
    "      x = array_ops.expand_dims(x, axis=1)\n",
    "    else:\n",
    "      x = np.expand_dims(x, 1)\n",
    "  return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行環境\n",
    "tensorflowのDataset APIを活用する場合、tensorflow内のkerasを利用するとエラーが出る不具合がある。\n",
    "```\n",
    "ValueError: Cannot take the length of shape with unknown rank.\n",
    "```\n",
    "https://stackoverflow.com/questions/53851793/valueerror-cannot-take-the-length-of-shape-with-unknown-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "sess = tf.Session()\n",
    "K.set_session( sess )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[ 'TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleDriveをマウントする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS is Windows: PASS mount google drive\n",
      "\n",
      "<< Display work dir >>\n",
      "file/dir :  .ipynb_checkpoints\n",
      "file/dir :  data\n",
      "file/dir :  mnist_cams\n",
      "file/dir :  mnist_pix2pix\n",
      "file/dir :  models\n",
      "file/dir :  mylib\n",
      "file/dir :  template.ipynb\n",
      "file/dir :  test.txt\n",
      "file/dir :  tmp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.name == 'nt':\n",
    "    print('OS is Windows: PASS mount google drive')\n",
    "    g_dir_work = '../colab/'\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    g_dir_work = '/content/drive/My Drive/colab/'\n",
    "\n",
    "# check mount point\n",
    "print('\\n<< Display work dir >>')\n",
    "for file in os.listdir(g_dir_work):\n",
    "    print( 'file/dir : ', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local Libraryパスを通す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if os.name == 'nt':# windows\n",
    "    lib_path='../colab/mylib'\n",
    "else:\n",
    "    print(os.getcwd())\n",
    "    lib_path='/content/drive/My Drive/colab/mylib/'\n",
    "sys.path.append(lib_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data.TextLineDatasetのサンプル\n",
    "https://deepage.net/tensorflow/2017/07/18/tensorflow-dataset-api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categories(object):\n",
    "    __instance = None\n",
    "    def __new__(cls, *args, **keys):\n",
    "        if cls.__instance is None:\n",
    "            cls.__instance = object.__new__(cls)\n",
    "        return cls.__instance\n",
    "\n",
    "    def __init__(self):\n",
    "            self.items = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9' ]\n",
    "            self.num   = len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "data = datasets.Dataset_mnist()\n",
    "data.load()\n",
    "input_file = data.save_for_textlinedataset(num=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "work_dir = '../colab/tmp'\n",
    "input_file = work_dir + '/input.txt'\n",
    "N = 100\n",
    "num_labels = Categories().num\n",
    "\n",
    "with open(input_file, 'w') as fp:\n",
    "    for i in range(N):\n",
    "        data = np.random.random(32).astype(np.float32)\n",
    "        label = int(np.random.random()* num_labels) # ラベル番号:0-(num_labels-1)\n",
    "        fp.writelines('{0}/{1:03d}.npy,{2}\\n'.format(work_dir, i, label))\n",
    "        np.save('{0}/{1:03d}.npy'.format(work_dir, i), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-122875ca6a1a>:18: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def to_index(label):\n",
    "    return Categories().items.index(label)\n",
    "\n",
    "def parse_csv(line):\n",
    "    [filename, category] = line.decode('utf-8').split(',')\n",
    "    return filename, to_index(category)\n",
    "\n",
    "def read_data(filename, label):\n",
    "    inputs = np.load(filename.decode('utf-8')).astype(np.float32) / 255.0\n",
    "    inputs = np.reshape(inputs, (inputs.shape[0], inputs.shape[1], 1))\n",
    "    return inputs, label\n",
    "\n",
    "def one_hot(data, label):\n",
    "    return data, tf.one_hot( label, Categories().num  )\n",
    "\n",
    "dataset = tf.data.TextLineDataset(input_file)\n",
    "#dataset = dataset.skip(1)   # 列の読み飛ばし\n",
    "dataset = dataset.map(lambda x  : tf.py_func(parse_csv, [x],    [tf.string,  tf.int32]))\n",
    "dataset = dataset.map(lambda x,y: tf.py_func(read_data, [x, y], [tf.float32, tf.int32]))\n",
    "dataset = dataset.map(one_hot)\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.shuffle(4)\n",
    "dataset = dataset.batch(4)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_elem = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "data ----------------------------------\n",
      "(4, 28, 28, 1)\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "labels ----------------------------------\n",
      "(4, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# datasetテスト\n",
    "val = sess.run(next_elem)\n",
    "\n",
    "print(len(val))\n",
    "print('\\ndata ----------------------------------')\n",
    "print(val[0].shape)\n",
    "print(val[0].max())\n",
    "print(val[0].min())\n",
    "#print(val[0])\n",
    "\n",
    "print('\\nlabels ----------------------------------')\n",
    "print(val[1].shape)\n",
    "print(val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練用モデル構築\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mhomm\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\mhomm\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "imgs (InputLayer)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 249,162\n",
      "Trainable params: 249,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "model = models.Model_mnist_classification()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 10\n",
    "steps_per_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 10s 3s/step - loss: 2.3300 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 309ms/step - loss: 2.3071 - acc: 0.0833\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 2.2950 - acc: 0.2500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 2.2942 - acc: 0.1667\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 250ms/step - loss: 2.3106 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 2.2585 - acc: 0.1667\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 2.2958 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 268ms/step - loss: 2.2629 - acc: 0.0833\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 2.2491 - acc: 0.2500\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 2.3191 - acc: 0.1667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.make_one_shot_iterator(), epochs=epochs, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 2.2635 - acc: 0.1667 \n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 250ms/step - loss: 2.3076 - acc: 0.0833\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 2.2712 - acc: 0.2500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 2.2767 - acc: 0.3333\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 2.2717 - acc: 0.0833\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 2.2556 - acc: 0.0833\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 2.1795 - acc: 0.3333\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 255ms/step - loss: 2.1299 - acc: 0.4167\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 251ms/step - loss: 2.1008 - acc: 0.3333\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 2.1128 - acc: 0.1667ETA: 0s - loss: 2.0808 - acc: 0.1250   \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
